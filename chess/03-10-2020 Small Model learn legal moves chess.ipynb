{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "03-10-2020 Small Model learn legal moves chess.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVuqEfg-H_Y4",
        "colab_type": "code",
        "colab": {},
        "outputId": "593e9ac6-beda-4b50-d304-5a6cadb03d98"
      },
      "source": [
        "import chess\n",
        "board = chess.Board()\n",
        "fen_data = board.fen().split(\" \")\n",
        "print(fen_data)\n",
        "board"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR', 'w', 'KQkq', '-', '0', '1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<svg height=\"400\" version=\"1.1\" viewBox=\"0 0 400 400\" width=\"400\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs><g class=\"white pawn\" id=\"white-pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-linecap=\"round\" stroke-width=\"1.5\" /></g><g class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-knight\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" style=\"fill:#000000; stroke:#000000;\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" /></g><g class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-bishop\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" id=\"white-rook\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" id=\"white-queen\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-king\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g class=\"black pawn\" id=\"black-pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" stroke=\"#000\" stroke-linecap=\"round\" stroke-width=\"1.5\" /></g><g class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-knight\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" style=\"fill:#ececec; stroke:#ececec;\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-bishop\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" id=\"black-rook\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-linejoin=\"miter\" stroke-width=\"1\" /></g><g class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" id=\"black-queen\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-king\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect class=\"square dark a1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"20\" y=\"335\" /><use transform=\"translate(20, 335)\" xlink:href=\"#white-rook\" /><rect class=\"square light b1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"65\" y=\"335\" /><use transform=\"translate(65, 335)\" xlink:href=\"#white-knight\" /><rect class=\"square dark c1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"110\" y=\"335\" /><use transform=\"translate(110, 335)\" xlink:href=\"#white-bishop\" /><rect class=\"square light d1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"155\" y=\"335\" /><use transform=\"translate(155, 335)\" xlink:href=\"#white-queen\" /><rect class=\"square dark e1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"200\" y=\"335\" /><use transform=\"translate(200, 335)\" xlink:href=\"#white-king\" /><rect class=\"square light f1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"245\" y=\"335\" /><use transform=\"translate(245, 335)\" xlink:href=\"#white-bishop\" /><rect class=\"square dark g1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"290\" y=\"335\" /><use transform=\"translate(290, 335)\" xlink:href=\"#white-knight\" /><rect class=\"square light h1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"335\" y=\"335\" /><use transform=\"translate(335, 335)\" xlink:href=\"#white-rook\" /><rect class=\"square light a2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"20\" y=\"290\" /><use transform=\"translate(20, 290)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark b2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"65\" y=\"290\" /><use transform=\"translate(65, 290)\" xlink:href=\"#white-pawn\" /><rect class=\"square light c2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"110\" y=\"290\" /><use transform=\"translate(110, 290)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark d2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"155\" y=\"290\" /><use transform=\"translate(155, 290)\" xlink:href=\"#white-pawn\" /><rect class=\"square light e2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"200\" y=\"290\" /><use transform=\"translate(200, 290)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark f2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"245\" y=\"290\" /><use transform=\"translate(245, 290)\" xlink:href=\"#white-pawn\" /><rect class=\"square light g2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"290\" y=\"290\" /><use transform=\"translate(290, 290)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark h2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"335\" y=\"290\" /><use transform=\"translate(335, 290)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark a3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"20\" y=\"245\" /><rect class=\"square light b3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"65\" y=\"245\" /><rect class=\"square dark c3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"110\" y=\"245\" /><rect class=\"square light d3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"155\" y=\"245\" /><rect class=\"square dark e3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"200\" y=\"245\" /><rect class=\"square light f3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"245\" y=\"245\" /><rect class=\"square dark g3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"290\" y=\"245\" /><rect class=\"square light h3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"335\" y=\"245\" /><rect class=\"square light a4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"20\" y=\"200\" /><rect class=\"square dark b4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"65\" y=\"200\" /><rect class=\"square light c4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"110\" y=\"200\" /><rect class=\"square dark d4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"155\" y=\"200\" /><rect class=\"square light e4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"200\" y=\"200\" /><rect class=\"square dark f4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"245\" y=\"200\" /><rect class=\"square light g4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"290\" y=\"200\" /><rect class=\"square dark h4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"335\" y=\"200\" /><rect class=\"square dark a5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"20\" y=\"155\" /><rect class=\"square light b5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"65\" y=\"155\" /><rect class=\"square dark c5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"110\" y=\"155\" /><rect class=\"square light d5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"155\" y=\"155\" /><rect class=\"square dark e5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"200\" y=\"155\" /><rect class=\"square light f5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"245\" y=\"155\" /><rect class=\"square dark g5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"290\" y=\"155\" /><rect class=\"square light h5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"335\" y=\"155\" /><rect class=\"square light a6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"20\" y=\"110\" /><rect class=\"square dark b6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"65\" y=\"110\" /><rect class=\"square light c6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"110\" y=\"110\" /><rect class=\"square dark d6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"155\" y=\"110\" /><rect class=\"square light e6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"200\" y=\"110\" /><rect class=\"square dark f6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"245\" y=\"110\" /><rect class=\"square light g6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"290\" y=\"110\" /><rect class=\"square dark h6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"335\" y=\"110\" /><rect class=\"square dark a7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"20\" y=\"65\" /><use transform=\"translate(20, 65)\" xlink:href=\"#black-pawn\" /><rect class=\"square light b7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"65\" y=\"65\" /><use transform=\"translate(65, 65)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark c7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"110\" y=\"65\" /><use transform=\"translate(110, 65)\" xlink:href=\"#black-pawn\" /><rect class=\"square light d7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"155\" y=\"65\" /><use transform=\"translate(155, 65)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark e7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"200\" y=\"65\" /><use transform=\"translate(200, 65)\" xlink:href=\"#black-pawn\" /><rect class=\"square light f7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"245\" y=\"65\" /><use transform=\"translate(245, 65)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark g7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"290\" y=\"65\" /><use transform=\"translate(290, 65)\" xlink:href=\"#black-pawn\" /><rect class=\"square light h7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"335\" y=\"65\" /><use transform=\"translate(335, 65)\" xlink:href=\"#black-pawn\" /><rect class=\"square light a8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"20\" y=\"20\" /><use transform=\"translate(20, 20)\" xlink:href=\"#black-rook\" /><rect class=\"square dark b8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"65\" y=\"20\" /><use transform=\"translate(65, 20)\" xlink:href=\"#black-knight\" /><rect class=\"square light c8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"110\" y=\"20\" /><use transform=\"translate(110, 20)\" xlink:href=\"#black-bishop\" /><rect class=\"square dark d8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"155\" y=\"20\" /><use transform=\"translate(155, 20)\" xlink:href=\"#black-queen\" /><rect class=\"square light e8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"200\" y=\"20\" /><use transform=\"translate(200, 20)\" xlink:href=\"#black-king\" /><rect class=\"square dark f8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"245\" y=\"20\" /><use transform=\"translate(245, 20)\" xlink:href=\"#black-bishop\" /><rect class=\"square light g8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"290\" y=\"20\" /><use transform=\"translate(290, 20)\" xlink:href=\"#black-knight\" /><rect class=\"square dark h8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"335\" y=\"20\" /><use transform=\"translate(335, 20)\" xlink:href=\"#black-rook\" /><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"42\" y=\"10\">a</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"42\" y=\"390\">a</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"87\" y=\"10\">b</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"87\" y=\"390\">b</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"132\" y=\"10\">c</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"132\" y=\"390\">c</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"177\" y=\"10\">d</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"177\" y=\"390\">d</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"222\" y=\"10\">e</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"222\" y=\"390\">e</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"267\" y=\"10\">f</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"267\" y=\"390\">f</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"312\" y=\"10\">g</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"312\" y=\"390\">g</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"357\" y=\"10\">h</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"357\" y=\"390\">h</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"10\" y=\"357\">1</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"390\" y=\"357\">1</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"10\" y=\"312\">2</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"390\" y=\"312\">2</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"10\" y=\"267\">3</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"390\" y=\"267\">3</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"10\" y=\"222\">4</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"390\" y=\"222\">4</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"10\" y=\"177\">5</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"390\" y=\"177\">5</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"10\" y=\"132\">6</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"390\" y=\"132\">6</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"10\" y=\"87\">7</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"390\" y=\"87\">7</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"10\" y=\"42\">8</text><text alignment-baseline=\"middle\" font-size=\"14\" text-anchor=\"middle\" x=\"390\" y=\"42\">8</text></svg>",
            "text/plain": [
              "Board('rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izKMCCoNH_Y9",
        "colab_type": "code",
        "colab": {},
        "outputId": "0dd17452-3cd7-421c-b9fe-09c16cde86aa"
      },
      "source": [
        "## all the possibilities\n",
        "one_hot_dictionary = {}\n",
        "pieces = ['r', \"n\", \"b\", \"q\", 'k', \"p\"]\n",
        "possibilities = pieces + [piece.upper() for piece in pieces]\n",
        "print(len(possibilities))\n",
        "\n",
        "one_hot_dictionary = {}\n",
        "one_hot_dictionary[\"1\"] = [0 for _ in range(13)]\n",
        "for i, possibility in enumerate(possibilities):\n",
        "    one_hot_dictionary[possibility] = [0 for _ in range(13)]\n",
        "    one_hot_dictionary[possibility][i] = 1\n",
        "one_hot_dictionary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'r': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'n': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'b': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'q': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'k': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'p': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'R': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              " 'N': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              " 'B': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              " 'Q': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              " 'K': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              " 'P': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrPFbW91H_Y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_numpy_board(board):\n",
        "    def transform_line(line):\n",
        "        result = \"\"\n",
        "        for character in line:\n",
        "            if character.isdigit():\n",
        "                for i in range(int(character)):\n",
        "                    result += \"1\"\n",
        "            else:\n",
        "                result += character\n",
        "        return result\n",
        "    \n",
        "    def compute_en_passant(ep_square):\n",
        "        def alg_to_coord(alg):\n",
        "            rank = 8 - int(alg[1])        # 0-7\n",
        "            file = ord(alg[0]) - ord('a') # 0-7 #WTF ord(\"a\")??\n",
        "            return rank, file\n",
        "        # renvoie une matrice de la taille dun jeu d'echec, contenant True si la case possede un \n",
        "        #pion que l'on peut manger en passant\n",
        "        en_passant = np.zeros((8, 8, 1), dtype=np.bool)\n",
        "        if ep_square != '-':\n",
        "            eps = alg_to_coord(ep_square)\n",
        "            en_passant[eps[0]][eps[1]] = True\n",
        "        return en_passant\n",
        "\n",
        "    fen_data = board.fen().split(\" \")\n",
        "    fen, turn, castling, ep_square, half_move_clock, fullmove_number = fen_data\n",
        "    en_passant = compute_en_passant(ep_square)\n",
        "    auxiliary_planes = [np.full((8, 8, 1), ('K' in castling), dtype=np.bool),\n",
        "                        np.full((8, 8, 1), ('Q' in castling), dtype=np.bool),\n",
        "                        np.full((8, 8, 1), ('k' in castling), dtype=np.bool),\n",
        "                        np.full((8, 8, 1), ('q' in castling), dtype=np.bool),\n",
        "                        en_passant]\n",
        "    \n",
        "    piece_information_plane = np.zeros((8,8, len(one_hot_dictionary)))\n",
        "    for i, line in enumerate(fen.split(\"/\")):\n",
        "        for j, case in enumerate(transform_line(line)):\n",
        "            piece_information_plane[i][j] = one_hot_dictionary[case]    \n",
        "    all_planes = auxiliary_planes + [piece_information_plane]\n",
        "    all_planes_numpy = np.concatenate(all_planes, axis=-1).astype(np.float32)\n",
        "    return all_planes_numpy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "L6jE2EfCH_ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_uci_labels():\n",
        "    \"\"\"\n",
        "    Creates the labels for the universal chess interface into an array and returns them\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    labels_array = []\n",
        "    letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] #indice colonnes echiquier\n",
        "    numbers = ['1', '2', '3', '4', '5', '6', '7', '8'] #indice lignes echiquier\n",
        "    promoted_to = ['q', 'r', 'b', 'n'] #list of the available promotion for the pawn\n",
        "\n",
        "    for l1 in range(8):\n",
        "        for n1 in range(8):\n",
        "            destinations = [(t, n1) for t in range(8)] + \\\n",
        "                           [(l1, t) for t in range(8)] + \\\n",
        "                           [(l1 + t, n1 + t) for t in range(-7, 8)] + \\\n",
        "                           [(l1 + t, n1 - t) for t in range(-7, 8)] + \\\n",
        "                           [(l1 + a, n1 + b) for (a, b) in\n",
        "                            [(-2, -1), (-1, -2), (-2, 1), (1, -2), (2, -1), (-1, 2), (2, 1), (1, 2)]]\n",
        "            for (l2, n2) in destinations:\n",
        "                if (l1, n1) != (l2, n2) and l2 in range(8) and n2 in range(8):\n",
        "                    move = letters[l1] + numbers[n1] + letters[l2] + numbers[n2]\n",
        "                    labels_array.append(move)\n",
        "    for l1 in range(8):\n",
        "        l = letters[l1]\n",
        "        for p in promoted_to:\n",
        "            labels_array.append(l + '2' + l + '1' + p)\n",
        "            labels_array.append(l + '7' + l + '8' + p)\n",
        "            if l1 > 0:\n",
        "                l_l = letters[l1 - 1]\n",
        "                labels_array.append(l + '2' + l_l + '1' + p)\n",
        "                labels_array.append(l + '7' + l_l + '8' + p)\n",
        "            if l1 < 7:\n",
        "                l_r = letters[l1 + 1]\n",
        "                labels_array.append(l + '2' + l_r + '1' + p)\n",
        "                labels_array.append(l + '7' + l_r + '8' + p)\n",
        "    return labels_array\n",
        "#tout les coups possibles\n",
        "all_moves = create_uci_labels()\n",
        "number_moves = len(all_moves)\n",
        "assert number_moves == 1968\n",
        "all_planes_numpy = get_numpy_board(board)\n",
        "shape_board = list(all_planes_numpy.shape)\n",
        "assert shape_board == [8,8,18]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "eTc667IVH_ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chess\n",
        "\n",
        "def get_label_moves(board):\n",
        "    labels = np.zeros((number_moves), dtype=np.bool)\n",
        "    legal_moves = [str(x) for x in list(board.legal_moves)]\n",
        "    for i, move in enumerate(all_moves):\n",
        "        if str(move) in legal_moves:\n",
        "            labels[i] = (1)\n",
        "    return labels\n",
        "def get_features(board):\n",
        "    return get_numpy_board(board)\n",
        "# get_features(board)\n",
        "\n",
        "def get_naive_reward(board):\n",
        "    return 1\n",
        "# list(get_label_moves(board))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ193BYxH_ZG",
        "colab_type": "code",
        "colab": {},
        "outputId": "4d23caa1-6968-47c8-c20c-c61f49222884"
      },
      "source": [
        "%%time\n",
        "board = chess.Board()\n",
        "\n",
        "#for a given board\n",
        "X = get_features(board)\n",
        "y = get_label_moves(board)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.58 ms, sys: 89 µs, total: 1.67 ms\n",
            "Wall time: 1.68 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vBPWA6TH_ZJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "b281de05-6d65-40dd-9768-f9ddef2ca3e5"
      },
      "source": [
        "print(board.fen())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbup8zZyH_ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_unique_identifier(board):\n",
        "    return str(board.board_fen()) + str(board.turn) + str(board.castling_rights) + str(board.ep_square)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQGrgNS5H_ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_moves_until_end(observations, board, dataset_size, max_number_moves):\n",
        "    if len(observations) == dataset_size or max_number_moves==0:\n",
        "        return\n",
        "    \n",
        "    if board.turn == chess.WHITE:\n",
        "        identifier = get_unique_identifier(board)\n",
        "        if identifier not in observations:\n",
        "                observations[identifier] = [get_features(board), get_label_moves(board)]\n",
        "                if len(observations) % int(dataset_size / 100) ==0:\n",
        "                    print(f\" {len(observations)} observations has been simulated\")\n",
        "    legal_moves = list(board.legal_moves)\n",
        "    if not (legal_moves):\n",
        "        return\n",
        "    random_move = np.random.choice(legal_moves)\n",
        "    board.push(random_move)\n",
        "    get_moves_until_end(observations, board , dataset_size, max_number_moves-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RJZQS-6H_ZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_dataset(max_number_moves=500, dataset_size=100000):\n",
        "    observations = {}\n",
        "    while len(observations) < dataset_size:\n",
        "        board = chess.Board()\n",
        "        get_moves_until_end(observations, board, dataset_size, max_number_moves)\n",
        "    X = np.zeros((dataset_size, 8,8,18), dtype=np.float32)\n",
        "    y = np.zeros((dataset_size, number_moves), dtype=np.int8)\n",
        "    for i, obs in enumerate(observations):\n",
        "        X[i] = observations[obs][0]\n",
        "        y[i] = observations[obs][1] #un peu redondant\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gPQbixOH_ZS",
        "colab_type": "code",
        "colab": {},
        "outputId": "0d266206-0928-489e-de9a-02c7aa70b79f"
      },
      "source": [
        "%%time\n",
        "dataset_size=10000\n",
        "X, y = generate_dataset(max_number_moves=200, dataset_size=dataset_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 100 observations has been simulated\n",
            " 200 observations has been simulated\n",
            " 300 observations has been simulated\n",
            " 400 observations has been simulated\n",
            " 500 observations has been simulated\n",
            " 600 observations has been simulated\n",
            " 700 observations has been simulated\n",
            " 800 observations has been simulated\n",
            " 900 observations has been simulated\n",
            " 1000 observations has been simulated\n",
            " 1100 observations has been simulated\n",
            " 1200 observations has been simulated\n",
            " 1300 observations has been simulated\n",
            " 1400 observations has been simulated\n",
            " 1500 observations has been simulated\n",
            " 1600 observations has been simulated\n",
            " 1700 observations has been simulated\n",
            " 1800 observations has been simulated\n",
            " 1900 observations has been simulated\n",
            " 2000 observations has been simulated\n",
            " 2100 observations has been simulated\n",
            " 2200 observations has been simulated\n",
            " 2300 observations has been simulated\n",
            " 2400 observations has been simulated\n",
            " 2500 observations has been simulated\n",
            " 2600 observations has been simulated\n",
            " 2700 observations has been simulated\n",
            " 2800 observations has been simulated\n",
            " 2900 observations has been simulated\n",
            " 3000 observations has been simulated\n",
            " 3100 observations has been simulated\n",
            " 3200 observations has been simulated\n",
            " 3300 observations has been simulated\n",
            " 3400 observations has been simulated\n",
            " 3500 observations has been simulated\n",
            " 3600 observations has been simulated\n",
            " 3700 observations has been simulated\n",
            " 3800 observations has been simulated\n",
            " 3900 observations has been simulated\n",
            " 4000 observations has been simulated\n",
            " 4100 observations has been simulated\n",
            " 4200 observations has been simulated\n",
            " 4300 observations has been simulated\n",
            " 4400 observations has been simulated\n",
            " 4500 observations has been simulated\n",
            " 4600 observations has been simulated\n",
            " 4700 observations has been simulated\n",
            " 4800 observations has been simulated\n",
            " 4900 observations has been simulated\n",
            " 5000 observations has been simulated\n",
            " 5100 observations has been simulated\n",
            " 5200 observations has been simulated\n",
            " 5300 observations has been simulated\n",
            " 5400 observations has been simulated\n",
            " 5500 observations has been simulated\n",
            " 5600 observations has been simulated\n",
            " 5700 observations has been simulated\n",
            " 5800 observations has been simulated\n",
            " 5900 observations has been simulated\n",
            " 6000 observations has been simulated\n",
            " 6100 observations has been simulated\n",
            " 6200 observations has been simulated\n",
            " 6300 observations has been simulated\n",
            " 6400 observations has been simulated\n",
            " 6500 observations has been simulated\n",
            " 6600 observations has been simulated\n",
            " 6700 observations has been simulated\n",
            " 6800 observations has been simulated\n",
            " 6900 observations has been simulated\n",
            " 7000 observations has been simulated\n",
            " 7100 observations has been simulated\n",
            " 7200 observations has been simulated\n",
            " 7300 observations has been simulated\n",
            " 7400 observations has been simulated\n",
            " 7500 observations has been simulated\n",
            " 7600 observations has been simulated\n",
            " 7700 observations has been simulated\n",
            " 7800 observations has been simulated\n",
            " 7900 observations has been simulated\n",
            " 8000 observations has been simulated\n",
            " 8100 observations has been simulated\n",
            " 8200 observations has been simulated\n",
            " 8300 observations has been simulated\n",
            " 8400 observations has been simulated\n",
            " 8500 observations has been simulated\n",
            " 8600 observations has been simulated\n",
            " 8700 observations has been simulated\n",
            " 8800 observations has been simulated\n",
            " 8900 observations has been simulated\n",
            " 9000 observations has been simulated\n",
            " 9100 observations has been simulated\n",
            " 9200 observations has been simulated\n",
            " 9300 observations has been simulated\n",
            " 9400 observations has been simulated\n",
            " 9500 observations has been simulated\n",
            " 9600 observations has been simulated\n",
            " 9700 observations has been simulated\n",
            " 9800 observations has been simulated\n",
            " 9900 observations has been simulated\n",
            " 10000 observations has been simulated\n",
            "CPU times: user 21.2 s, sys: 591 ms, total: 21.8 s\n",
            "Wall time: 22.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGtscMnSH_ZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"X.npy\", X)\n",
        "np.save(\"y.npy\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcIx2iOLH_ZY",
        "colab_type": "text"
      },
      "source": [
        "## Est ce que j'ai tout les elements pour entrainer mon IA?\n",
        "\n",
        "- [x] representer la position d'une partie d'echecs sous forme de matrice numpy \n",
        "- [x] la liste de tout les coups possibles pour une partie d'echecs (case a to case b etc..)\n",
        "- [x] connaitre la liste des coups valides pour une position existante (`list(board.legal_moves)`)\n",
        "- [x] Definition d'un mini modele qui prevoit valeur et une probabilite pour chaque coup (je fais ca maintenant)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjdhdPd-H_ZY",
        "colab_type": "code",
        "colab": {},
        "outputId": "076f6c49-ead5-469f-b624-79700321868d"
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, Flatten, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "def naive_model_value_and_move_prediction():\n",
        "    NUMBER_FILTERS = 8\n",
        "    #take a numpy array representing a board as input, and who plays first, and then return\n",
        "    # the value of a game, number between -1 and 1\n",
        "    board = Input(shape=(shape_board))\n",
        "    \n",
        "    features = Conv2D(filters=NUMBER_FILTERS,kernel_size=3,activation=\"relu\", padding=\"same\")(board)\n",
        "    features = Conv2D(filters=2, kernel_size=3,activation=\"relu\", padding=\"same\")(features)\n",
        "    print(features.shape)\n",
        "    features = Flatten()(features)\n",
        "#     value_prediction = Dense(1, activation=\"sigmoid\")(features) #TRY WITH TANGENT FOR output between -1 and 1\n",
        "    policy_prediction = Dense(number_moves, activation=\"sigmoid\")(features)\n",
        "\n",
        "    model = Model(board, policy_prediction)\n",
        "    model.compile(loss=[\"binary_crossentropy\"], optimizer=\"Adam\")\n",
        "    model.summary()\n",
        "    return model\n",
        "model = naive_model_value_and_move_prediction()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 8, 8, 2)\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 8, 8, 18)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 8)           1304      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 2)           146       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1968)              253872    \n",
            "=================================================================\n",
            "Total params: 255,322\n",
            "Trainable params: 255,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4B6Of6FH_Za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X, y, epochs=100) # loss: 0.0344 in ~2 epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANN-yJOMH_Zc",
        "colab_type": "code",
        "colab": {},
        "outputId": "584f01d4-8e52-44a6-f6d6-1940d334cc6d"
      },
      "source": [
        "def model_moves():\n",
        "    NUMBER_FILTERS = 16\n",
        "    #take a numpy array representing a board as input, and who plays first, and then return\n",
        "    # the value of a game, number between -1 and 1\n",
        "    board = Input(shape=(shape_board))\n",
        "    \n",
        "    features = Conv2D(filters=NUMBER_FILTERS,kernel_size=3,activation=\"relu\", padding=\"same\")(board)\n",
        "    features = BatchNormalization()(features)\n",
        "    features = Conv2D(filters=NUMBER_FILTERS, kernel_size=3,activation=\"relu\", padding=\"same\")(features)\n",
        "    features = BatchNormalization()(features)\n",
        "    features = Conv2D(filters=2, kernel_size=3,activation=\"relu\", padding=\"same\")(features)\n",
        "    print(features.shape)\n",
        "    features = Flatten()(features)\n",
        "#     value_prediction = Dense(1, activation=\"sigmoid\")(features) #TRY WITH TANGENT FOR output between -1 and 1\n",
        "    policy_prediction = Dense(number_moves, activation=\"sigmoid\")(features)\n",
        "\n",
        "    model = Model(board, policy_prediction)\n",
        "    model.compile(loss=[\"binary_crossentropy\"], optimizer=\"Adam\")\n",
        "    model.summary()\n",
        "    return model\n",
        "model = model_moves()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 8, 8, 2)\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 8, 8, 18)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 16)          2608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 2)           290       \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1968)              253872    \n",
            "=================================================================\n",
            "Total params: 259,218\n",
            "Trainable params: 259,154\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv7OhICfH_Ze",
        "colab_type": "code",
        "colab": {},
        "outputId": "0e9da2b7-2073-4a92-84c6-b10206d9a110"
      },
      "source": [
        "model.fit(X, y, epochs=100) # loss: 0.0344 in ~2 epochs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Error when checking input: expected input_5 to have shape (8, 8, 18) but got array with shape (8, 8, 36)",
          "traceback": [
            "\u001b[0;31m-------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-175-5dd8978c96b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# loss: 0.0344 in ~2 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_5 to have shape (8, 8, 18) but got array with shape (8, 8, 36)"
          ]
        }
      ]
    }
  ]
}